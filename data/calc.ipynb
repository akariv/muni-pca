{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using checkpoint data from .checkpoints/lamas_muni_names\n",
      "select name, header, value from lamas_muni where name in ('אבו גוש','אבו סנאן','אבן יהודה','אום אל-פחם','אופקים','אור יהודה','אורנית','אור עקיבא','אזור','אילת','אכסאל','אל-בטוף','אלונה','אליכין','אלעד','אלפי מנשה','אלקנה','אל קסום','אעבלין','אפרת','אריאל','אשדוד','אשכול','אשקלון','באקה אל-גרביה','באר טוביה','באר יעקב','באר שבע','בוסתן אל-מרג''','בועיינה-נוג''ידאת','בוקעאתא','ביר אל-מכסור','בית אל','בית אריה-עופרים','בית ג''ן','בית דגן','ביתר עילית','בית שאן','בית שמש','בני ברק','בנימינה-גבעת עדה','בני עי\"ש','בני שמעון','בסמ\"ה','בסמת טבעון','בענה','ברנר','בת ים','גבעת זאב','גבעתיים','גבעת שמואל','ג''דיידה-מכר','גדרה','גדרות','גולן','ג''ולס','גוש עציון','גזר','ג''לג''וליה','גן יבנה','גן רווה','גני תקווה','ג''סר א-זרקא','ג''ש (גוש חלב)','ג''ת','דאלית אל-כרמל','דבורייה','דייר אל-אסד','דייר חנא','דימונה','דרום השרון','הגלבוע','הגליל העליון','הגליל התחתון','הוד השרון','הערבה התיכונה','הר אדר','הר חברון','הרצליה','זבולון','זכרון יעקב','זמר','זרזיר','חבל אילות','חבל יבנה','חבל מודיעין','חדרה','חולון','חוף אשקלון','חוף הכרמל','חוף השרון','חורה','חורפיש','חיפה','חצור הגלילית','חריש','טבריה','טובא-זנגרייה','טורעאן','טייבה','טירה','טירת כרמל','טמרה','יאנוח-ג''ת','יבנאל','יבנה','יהוד-מונוסון','יואב','יסוד המעלה','יפיע','יקנעם עילית','ירוחם','ירושלים','ירכא','כאבול','כאוכב אבו אל-היג''א','כוכב יאיר','כסיפה','כסרא-סמיע','כעביה-טבאש-חג''אג''רה','כפר ברא','כפר ורדים','כפר יאסיף','כפר יונה','כפר כמא','כפר כנא','כפר מנדא','כפר סבא','כפר קאסם','כפר קרע','כפר שמריהו','כפר תבור','כרמיאל','לב השרון','להבים','לוד','לכיש','לקיה','מבואות החרמון','מבשרת ציון','מגאר','מג''ד אל-כרום','מגדל','מגדל העמק','מג''דל שמס','מגידו','מגילות ים המלח','מודיעין-מכבים-רעות','מודיעין עילית','מזכרת בתיה','מזרעה','מטה אשר','מטה בנימין','מטה יהודה','מטולה','מיתר','מנשה','מסעדה','מעיליא','מעלה אדומים','מעלה אפרים','מעלה יוסף','מעלה עירון','מעלות-תרשיחא','מצפה רמון','מרום הגליל','מרחבים','משגב','משהד','נהרייה','נווה מדבר','נוף הגליל','נחל שורק','נחף','נס ציונה','נצרת','נשר','נתיבות','נתניה','סאג''ור','סביון','סח''נין','ע''ג''ר','עומר','עיילבון','עילוט','עין מאהל','עין קנייא','עכו','עמנואל','עמק הירדן','עמק המעיינות','עמק חפר','עמק יזרעאל','עספיא','עפולה','עראבה','ערבות הירדן','ערד','ערערה','ערערה-בנגב','פוריידיס','פסוטה','פקיעין (בוקייעה)','פרדס חנה-כרכור','פרדסייה','פתח תקווה','צפת','קדומים','קדימה-צורן','קלנסווה','קצרין','קריית אונו','קריית ארבע','קריית אתא','קריית ביאליק','קריית גת','קריית טבעון','קריית ים','קריית יערים','קריית מוצקין','קריית מלאכי','קריית עקרון','קריית שמונה','קרני שומרון','ראמה','ראש העין','ראשון לציון','ראש פינה','רהט','רחובות','ריינה','רכסים','רמלה','רמת גן','רמת השרון','רמת ישי','רמת נגב','רעננה','שבלי - אום אל-גנם','שגב-שלום','שדות דן','שדות נגב','שדרות','שוהם','שומרון','שלומי','שעב','שער הנגב','שפיר','שפרעם','תל אביב-יפו','תל מונד','תל שבע','תמר') order by year\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adam/.pyenv/versions/3.12.1/lib/python3.12/site-packages/dataflows/processors/join.py:189: UserWarning: For the `join` processor the `full=True` flag is deprecated. Please use the \"mode\" parameter instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using checkpoint data from .checkpoints/lamas_muni\n",
      "using checkpoint data from .checkpoints/voting_stats\n"
     ]
    }
   ],
   "source": [
    "import dataflows as DF\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import re\n",
    "\n",
    "DB = 'postgresql://readonly:readonly@db.datacity.org.il/datasets'\n",
    "\n",
    "ENTITIES_URL = 'https://redash.hasadna.org.il/api/queries/1361/results.json?api_key=UDd9IGDUTqM8seDggkaCezRGO7kI440AINdrRkzS'\n",
    "ENTITIES = requests.get(ENTITIES_URL).json()['query_result']['data']['rows']\n",
    "ENTITIES = {str(x['symbol']): x['id'] for x in ENTITIES}\n",
    "ENTITIES['40'] = '500243407'\n",
    "\n",
    "SUPPORTS_URL = 'https://redash.hasadna.org.il/api/queries/1362/results.json?api_key=Jv9V86TxVc9lbh5a2jVfTlTT25Z0o4kDnlfBX8DX'\n",
    "SUPPORTS = requests.get(SUPPORTS_URL).json()['query_result']['data']['rows']\n",
    "\n",
    "SUPPORT_PREFIXES = [\n",
    "    ('045212', 'מורשת'),\n",
    "    ('045213', 'התיישבות'),\n",
    "    ('3308', 'התיישבות'),\n",
    "    ('99', 'התיישבות'),\n",
    "    ('045215', 'שוויון חברתי, חדשנות ודיגיטציה'),\n",
    "    ('0457', 'שוויון חברתי, חדשנות ודיגיטציה'),\n",
    "    ('83', 'שוויון חברתי, חדשנות ודיגיטציה'),\n",
    "    ('0456', 'שיתוף פעולה'),\n",
    "    ('0464', 'פיתוח הנגב והגליל'),\n",
    "    ('0620', 'חרבות ברזל'),\n",
    "    ('0622', 'תמיכה בשירותי דת'),\n",
    "    ('22', 'תמיכה בשירותי דת'),\n",
    "    ('18110101', 'מענקי איזון'),\n",
    "    ('18110103', 'מענק הבירה'),\n",
    "    ('18110301', 'מענקי איזון'),\n",
    "    ('18110303', 'מענק הבירה'),\n",
    "    ('18110344', 'מענק הבירה'),\n",
    "    ('1811', 'מענקים ותמיכות אחרות'),\n",
    "    ('1812', 'מענקי הקרן לצמצום פערים'),\n",
    "    ('1940', 'מיזמי מדע'),\n",
    "    ('1942', 'פעולות תרבות'),\n",
    "    ('1943', 'תמיכה בספורט'),\n",
    "    ('2060', 'חינוך בלתי פורמאלי והעשרה'),\n",
    "    ('2067', 'חינוך בלתי פורמאלי והעשרה'),\n",
    "    ('2061', 'חינוך מיוחד'),\n",
    "    ('2062', 'גני ילדים'),\n",
    "    ('2063', 'חינוך יסודי'),\n",
    "    ('2064', 'חינוך תיכוני'),\n",
    "    ('2069', 'חינוך ליהדות'),\n",
    "    ('20', 'תמיכות במערכת החינוך'),\n",
    "    ('23', 'תמיכות במערכת הרווחה'),\n",
    "    ('24', 'תמיכות משרד הבריאות'),\n",
    "    ('26', 'קידום איכות הסביבה'),\n",
    "    ('30', 'קליטת עלייה'),\n",
    "    ('3309', 'מנהלת תנופה'),\n",
    "    ('33', 'חקלאות ובעלי חיים'),\n",
    "    ('36', 'סבסוד מעונות יום ומשפחתונים'),\n",
    "    ('37', 'פעולות תיירותיות'),\n",
    "    ('38', 'תמיכה בעסקים'),\n",
    "    ('40', 'תחבורה'),\n",
    "    ('79', 'תחבורה'),\n",
    "    ('54', 'תכנון'),\n",
    "    ('60', 'תשתיות חינוך'),\n",
    "    ('73', 'משק המים'),\n",
    "]\n",
    "\n",
    "MANY_WS = re.compile(r'\\s+')\n",
    "ENTITY_SUPPORTS = {}\n",
    "for entity_id in ENTITIES.values():\n",
    "    entity_supports = [x for x in SUPPORTS if x['entity_id'] == entity_id]\n",
    "\n",
    "    buckets = {}\n",
    "    usage = []\n",
    "    for support in entity_supports:\n",
    "        code = support['budget_code']\n",
    "        for prefix, bucket in SUPPORT_PREFIXES:\n",
    "            if code.startswith(prefix):\n",
    "                rec = buckets.setdefault(bucket, dict(paid=0, approved=0))\n",
    "                rec['paid'] += support['paid']\n",
    "                rec['approved'] += support['approved']\n",
    "                break\n",
    "        if support['approved'] > 0 and prefix and 'מענק' not in prefix:\n",
    "            if support['paid'] / support['approved'] > 1:\n",
    "                usage.append(1)\n",
    "            else:\n",
    "                usage.append(support['paid'] / support['approved'])\n",
    "\n",
    "    buckets = [dict(name=k, **v) for k, v in buckets.items()]\n",
    "    # for b in buckets:\n",
    "    #     b['usage'] = b['paid'] / b['approved'] if b['approved'] > 0 else 0\n",
    "    supports = sorted(buckets, key=lambda x: x['paid'], reverse=True)[:10]\n",
    "\n",
    "    buckets = {}\n",
    "    for support in entity_supports:\n",
    "        key = (support['supporting_ministry'], MANY_WS.sub(' ', support['support_title']))\n",
    "        rec = buckets.setdefault(key, dict(paid=0, approved=0))\n",
    "        rec['paid'] += support['paid']\n",
    "        rec['approved'] += support['approved']\n",
    "    buckets = [dict(ministry=k[0], title=k[1], **v) for k, v in buckets.items()]\n",
    "    top = sorted(buckets, key=lambda x: x['paid'], reverse=True)[:10]\n",
    "    usage = sum(usage) / len(usage) if usage else 0\n",
    "\n",
    "    ENTITY_SUPPORTS[entity_id] = {\n",
    "        'supports': supports,\n",
    "        'top': top,\n",
    "        'usage': usage,\n",
    "    }\n",
    "\n",
    "NAMES_QUERY = 'select distinct name from lamas_muni where year=2021'\n",
    "all_city_names = DF.Flow(\n",
    "    DF.load(DB, query=NAMES_QUERY, name='names'),\n",
    "    DF.checkpoint('lamas_muni_names'),\n",
    ").results()[0][0]\n",
    "all_city_names = [x['name'] for x in all_city_names]\n",
    "names = [x.replace(\"'\", \"''\") for x in all_city_names]\n",
    "names = ','.join(f\"'{x}'\" for x in names)\n",
    "\n",
    "QUERY = f'select year, name, header, value from lamas_muni where name in ({names}) order by year'\n",
    "print(QUERY)\n",
    "\n",
    "DATA = DF.Flow(\n",
    "    DF.load(DB, query=QUERY, name='lamas_muni'),\n",
    "    DF.filter_rows(lambda row: row['value'] is not None),\n",
    "    DF.filter_rows(lambda row: (row['value'] and row['value'] != '0' or\n",
    "                                row['header'] not in ('הוצאות בתקציב הרגיל - סה\"כ הוצאות בתקציב רגיל (אלפי ש\"ח)', 'הכנסות בתקציב הרגיל - חיוב ארנונה סך הכל (שטח באלפי מ\"ר)'))),\n",
    "    DF.filter_rows(lambda row: row['year'] != 2021 or row['name'] not in (\n",
    "        'בית שאן', 'נצרת', 'קריית שמונה', 'בוקעאתא', 'גן יבנה', 'חריש', 'משהד', 'קדימה-צורן', 'תל שבע'\n",
    "    )),\n",
    "    DF.join_with_self('lamas_muni', ['name', 'header'], dict(\n",
    "        name=None,\n",
    "        header=None,\n",
    "        value=dict(name='value', aggregate='last')\n",
    "    )),\n",
    "    DF.checkpoint('lamas_muni'),\n",
    ").results()[0][0]\n",
    "\n",
    "entity_id_rows = []\n",
    "for row in DATA:\n",
    "    if row['header'] == 'כללי - סמל הרשות':\n",
    "        entity_id = ENTITIES.get(str(row['value']))\n",
    "        if entity_id:\n",
    "            entity_id_rows.append({'name': row['name'], 'header': 'entity_id', 'value': entity_id})\n",
    "DATA.extend(entity_id_rows)\n",
    "\n",
    "voter_columns = ['מצביעים למפלגות חרדיות', 'מצביעי שמאל', 'מצביעי ציונות דתית', 'מצביעי ימין', 'מצביעי מרכז', 'מצביעים למפלגות ערביות']\n",
    "def normalize_voters(cols):\n",
    "    def func(row):\n",
    "        total = sum(row[col] or 0 for col in cols)\n",
    "        for col in cols:\n",
    "            row[col] = row[col] / total * 100\n",
    "        return row\n",
    "    return func\n",
    "\n",
    "VOTERS = DF.Flow(\n",
    "    DF.load('https://docs.google.com/spreadsheets/d/16FKQ51z5ijkqle4dXpCI-qyCtgNxG-8zp_moWN1QEGE/edit#gid=1595307595'),\n",
    "    DF.set_type('מצביעי.+', type='number'),\n",
    "    normalize_voters(voter_columns),\n",
    "    DF.add_field('קואליציה', 'number', lambda r: r['מצביעי ימין'] + r['מצביעים למפלגות חרדיות'] + r['מצביעי ציונות דתית']),\n",
    "    DF.add_field('דתיים', 'number', lambda r: r['מצביעי ציונות דתית'] + r['מצביעים למפלגות חרדיות']),\n",
    "    DF.checkpoint('voting_stats')\n",
    ").results()[0][0]\n",
    "VOTERS_IDX = [x.pop('name') for x in VOTERS]\n",
    "\n",
    "voter_columns.append('קואליציה')\n",
    "voter_columns.append('דתיים')\n",
    "VOTERS = pd.DataFrame(VOTERS, index=VOTERS_IDX, columns=voter_columns).astype(np.float64)\n",
    "\n",
    "SETT_TO_MUNI = DF.Flow(\n",
    "    DF.load('https://docs.google.com/spreadsheets/d/16FKQ51z5ijkqle4dXpCI-qyCtgNxG-8zp_moWN1QEGE/edit#gid=594850932'),\n",
    "    DF.select_fields(['שם_ישוב', 'שם_מועצה']),\n",
    "    DF.set_type('שם_מועצה', transform=lambda v, row: v or row['שם_ישוב']),\n",
    "    DF.rename_fields({\n",
    "        'שם_ישוב': 'name',\n",
    "        'שם_מועצה': 'muni'\n",
    "    }),\n",
    "    DF.checkpoint('settlement_to_muni')\n",
    ").results()[0][0]\n",
    "SETT_TO_MUNI = sorted(filter(lambda x: x['muni'] in all_city_names, SETT_TO_MUNI), key=lambda x: x['name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "IGNORE_HEADERS = [\n",
    "    'כללי - שנת קבלת מעמד מוניציפלי'\n",
    "]\n",
    "\n",
    "clean = []\n",
    "for row in DATA:\n",
    "    header = row['header']\n",
    "    value = row['value']\n",
    "    if header not in ('entity_id', ):\n",
    "        try:\n",
    "            value = float(value)\n",
    "        except:\n",
    "            try:\n",
    "                value = int(value)\n",
    "            except:\n",
    "                name = None\n",
    "                pass\n",
    "    if value is not None:\n",
    "        if header == 'דמוגרפיה - שיעור פטירות תינוקות ל-1,000 לידות חי (אחוז)':\n",
    "            value = abs(value)\n",
    "        clean.append(dict(\n",
    "            name=row['name'],\n",
    "            header=header,\n",
    "            value=value\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "closing parenthesis ']' does not match opening parenthesis '(' on line 124 (592344376.py, line 128)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[2], line 128\u001b[0;36m\u001b[0m\n\u001b[0;31m    ]\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m closing parenthesis ']' does not match opening parenthesis '(' on line 124\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(clean)\n",
    "\n",
    "# Pivot the data to get cities as rows and indicators as columns\n",
    "pivoted_df = df.pivot(index='name', columns='header', values='value')\n",
    "\n",
    "for col in voter_columns:\n",
    "    pivoted_df[col] = VOTERS[col]\n",
    "pivoted_df['בריאות - שיעור מקרי סרטן ממוצע לשנה ל-100,000 תושבים'] = pivoted_df['בריאות - שיעור מקרי סרטן ממוצע לשנה ל-100,000 תושבים, גברים']  + pivoted_df['בריאות - שיעור מקרי סרטן ממוצע לשנה ל-100,000 תושבים, נשים']\n",
    "pivoted_df['דמוגרפיה - דרוזים (אחוז)'] = pivoted_df['דמוגרפיה - דרוזים (אחוז)'].fillna(0)\n",
    "pivoted_df['דמוגרפיה - יהודים (אחוז)'] = pivoted_df['דמוגרפיה - יהודים (אחוז)'].fillna(0)\n",
    "pivoted_df['דמוגרפיה - מוסלמים (אחוז)'] = pivoted_df['דמוגרפיה - מוסלמים (אחוז)'].fillna(0)\n",
    "pivoted_df['דמוגרפיה - נוצרים (אחוז)'] = pivoted_df['דמוגרפיה - נוצרים (אחוז)'].fillna(0)\n",
    "pivoted_df['הוצאות מנוכות בתקציב הרגיל - חינוך (אלפי ש\"ח)'] = pivoted_df['הוצאות בתקציב הרגיל - חינוך (אלפי ש\"ח)'].fillna(0) - pivoted_df['הכנסות בתקציב הרגיל - הכנסות של הרשות ממשרד החינוך (אלפי ש\"ח)'].fillna(0)\n",
    "\n",
    "POP = pivoted_df['דמוגרפיה - אוכלוסייה (סה\"כ)'] / 1000\n",
    "EXPENSE = pivoted_df['הוצאות בתקציב הרגיל - סה\"כ הוצאות בתקציב רגיל (אלפי ש\"ח)']\n",
    "AREA = pivoted_df['שימושי קרקע - סך הכל שטח שיפוט (שטח בקמ\"ר)'].replace({np.nan: None})\n",
    "ARNONA_AREA = pivoted_df['הכנסות בתקציב הרגיל - חיוב ארנונה סך הכל (שטח באלפי מ\"ר)']\n",
    "STUDENTS = POP * pivoted_df['דמוגרפיה - בני 0-17 (אחוז באוכלוסייה)'] / 100\n",
    "\n",
    "configuration = [\n",
    "    ('דירות שנבנו ב-2021', 'בנייה ודיור - גמר בנייה: מספר דירות (סה\"כ)', 'POP', '1'),\n",
    "    ('דירות למגורים', 'בנייה ודיור - מספר דירות למגורים לפי מרשם מבנים ודירות (סה\"כ)', 'POP', '1'),\n",
    "    ('מקרי סכרת לשנה', 'בריאות - שיעור מקרי סכרת ממוצע לשנה ל-1,000 תושבים', None, '1'),\n",
    "    ('מקרי סרטן לשנה', 'בריאות - שיעור מקרי סרטן ממוצע לשנה ל-100,000 תושבים', None, '1'),\n",
    "    ('פטירות לשנה', 'דמוגרפיה - פטירות (סה\"כ)', 'POP', '1'),\n",
    "    ('פטירת תינוקות', 'דמוגרפיה - שיעור פטירות תינוקות ל-1,000 לידות חי (אחוז)', None, '1'),\n",
    "    ('לידות לשנה', 'דמוגרפיה - לידות חי (סה\"כ)', 'POP', '1'),\n",
    "    ('שיעור פריון', 'בריאות - שיעור פיריון כולל ל-1,000 תושבים', None),\n",
    "    ('ריבוי אוכלוסיה', 'דמוגרפיה - ריבוי טבעי ל-1,000 תושבים (סה\"כ)', None),\n",
    "    ('טמפרטורה ממוצעת באוגוסט', \"גיאוגרפיה - טמפ' ממוצעות באוגוסט (מעלות צלסיוס)\", None),\n",
    "    ('משקעים במ״מ', 'גיאוגרפיה - כמות משקעים ממוצעת במ\"מ', None),\n",
    "    ('מרחק מתל אביב', 'מדד פריפריאליות - ערך מדד', None),\n",
    "    ('שטח', 'גיאוגרפיה - סך הכל שטח (קמ\"ר)', None),\n",
    "    ('מספר תושבים', 'דמוגרפיה - אוכלוסייה (סה\"כ)', None),\n",
    "    ('צעירים מתחת לגיל 17', 'דמוגרפיה - בני 0-17 (אחוז באוכלוסייה)', None, '1'),\n",
    "    ('מבוגרים מעל גיל 65', 'דמוגרפיה - בני 65 ומעלה (אחוז באוכלוסייה)', None, '1'),\n",
    "    ('קצב גידול האוכלוסיה', 'דמוגרפיה - גידול האוכלוסייה (אחוז)', None),\n",
    "    ('דרוזים', 'דמוגרפיה - דרוזים (אחוז)', None, '1'),\n",
    "    ('יהודים', 'דמוגרפיה - יהודים (אחוז)', None, '1'),\n",
    "    ('מוסלמים', 'דמוגרפיה - מוסלמים (אחוז)', None, '1'),\n",
    "    ('נוצרים', 'דמוגרפיה - נוצרים (אחוז)', None, '1'),\n",
    "    ('נישאים', 'דמוגרפיה - נישאים (סה\"כ)', 'POP', '1'),\n",
    "    ('מתגרשים', 'דמוגרפיה - מתגרשים (סה\"כ)', 'POP', '1'),\n",
    "    ('עולים חדשים', 'דמוגרפיה - עולי 1990+ (אחוז)', None, '1'),\n",
    "    ('צפיפות אוכלוסיה', 'דמוגרפיה - צפיפות אוכלוסייה לשטח בנוי למגורים (נפשות לקמ\"ר)', None),\n",
    "    ('מדד חברתי-כלכלי', 'מדד חברתי-כלכלי - ערך מדד', None),\n",
    "    ('הוצאה לתלמיד על חינוך', 'הוצאות מנוכות בתקציב הרגיל - חינוך (אלפי ש\"ח)', 'STUDENTS', '4'),\n",
    "    ('הוצאה לנפש על רווחה', 'הוצאות בתקציב הרגיל - רווחה (אלפי ש\"ח)', 'POP', '1'),\n",
    "    ('הוצאה לנפש על תרבות', 'הוצאות בתקציב הרגיל - תרבות (אלפי ש\"ח)', 'POP', '1'),\n",
    "    ('הכנסות ארנונה לא למגורים', 'הכנסות בתקציב הרגיל - ארנונה לא למגורים (גבייה) (אלפי ש\"ח)', 'EXPENSE', '2'),\n",
    "    ('הכנסות ארנונה למגורים', 'הכנסות בתקציב הרגיל - ארנונה למגורים (גבייה) (אלפי ש\"ח)', 'EXPENSE', '2'),\n",
    "    ('הכנסות מלוות איזון', 'הכנסות בתקציב הרגיל - מלוות לאיזון (אלפי ש\"ח)', 'EXPENSE', '2'),\n",
    "    ('השתתפות משרדי הממשלה', 'הכנסות בתקציב הרגיל - הכנסות מהממשלה (אלפי ש\"ח)', 'EXPENSE', '2'),\n",
    "    ('גירעון', 'נתוני תקציב - עודף/גירעון - גירעון שנתי בתקציב הרגיל (אלפי ש\"ח)', 'EXPENSE', '2'),\n",
    "    ('אחוז גביית ארנונה', 'הכנסות בתקציב הרגיל - ארנונה למגורים (יחס גבייה ב-% לכלל החיובים)', None),\n",
    "    ('שטח מגורים', 'הכנסות בתקציב הרגיל - חיוב ארנונה למגורים (שטח באלפי מ\"ר)', 'ARNONA_AREA', '3'),\n",
    "    ('שטח חקלאי', 'הכנסות בתקציב הרגיל - חיוב ארנונה לאדמה חקלאית (שטח באלפי מ\"ר)', 'ARNONA_AREA', '3'),\n",
    "    ('שטח עסקים', 'הכנסות בתקציב הרגיל - חיוב ארנונה לעסקים (שטח באלפי מ\"ר)', 'ARNONA_AREA', '3'),\n",
    "    ('זכאים לבגרות', 'חינוך והשכלה - זכאים לתעודת בגרות מבין תלמידי כיתות יב (אחוז)', None),\n",
    "    ('ממוצע תלמידים לכיתה', 'חינוך והשכלה - ממוצע תלמידים לכיתה (סה\"כ)', None),\n",
    "    ('סטודנטים', 'חינוך והשכלה - סטודנטים מתוך אוכלוסיית בני 20-25 (אחוז)', None, '1'),\n",
    "    ('תלמידים למורה', 'חינוך והשכלה - עובדי הוראה - ממוצע תלמידים למורה', None),\n",
    "    ('תלמידים נושרים', 'חינוך והשכלה - תלמידים נושרים (אחוז)', None),\n",
    "    ('מורשעים', 'פשיעה ומשפט - מבוגרים תושבי ישראל המורשעים בדין, שיעור ל-1,000 בני 19 ומעלה', None, '1'),\n",
    "    ('פארקים', 'שימושי קרקע - גינון לנוי פארק ציבורי (שטח בקמ\"ר)', 'AREA', '3'),\n",
    "    ('מקבלי דמי אבטלה', 'שכר ורווחה - אחוז מקבלי דמי אבטלה מבני 67-20 (שנתי)', None, '1'),\n",
    "    ('מקבלי הבטחת הכנסה', 'שכר ורווחה - מקבלי הבטחת הכנסה (נפשות)', 'POP', '1'),\n",
    "    ('מרוויחי שכר מינימום', 'שכר ורווחה - שכירים המשתכרים עד שכר מינימום (אחוז)', None, '1'),\n",
    "    ('אי שויון כלכלי', \"שכר ורווחה - מדד אי-השוויון - שכירים (מדד ג'יני, 0 שוויון מלא)\", None),\n",
    "    ('ילדים במשפחות עם 5+ ילדים', 'שכר ורווחה - מספר הילדים מקבלי קצבאות בגין ילדים במשפחות עם 5 ילדים ומעלה', 'POP', '1'),\n",
    "    ('שכירים', 'שכר ורווחה - מספר השכירים (סה\"כ)', 'POP', '1'),\n",
    "    ('עצמאים', 'שכר ורווחה - מספר העצמאים (סה\"כ)', 'POP', '1'),\n",
    "    ('שכר ממוצע', 'שכר ורווחה - שכר חודשי ממוצע של שכירים (ש\"ח)', None),\n",
    "    ('מצביעים למפלגות חרדיות', 'מצביעים למפלגות חרדיות', None, '1'),\n",
    "    ('מצביעי שמאל', 'מצביעי שמאל', 'POP', '1'),\n",
    "    ('מצביעי ימין', 'מצביעי ימין', 'POP', '1'),\n",
    "    ('מצביעי מרכז', 'מצביעי מרכז', 'POP', '1'),\n",
    "    ('מצביעים למפלגות ערביות', 'מצביעים למפלגות ערביות', 'POP', '1'),\n",
    "    ('מצביעים למפלגות הקואליציה', 'קואליציה', 'POP', '1'),\n",
    "    ('מצביעים למפלגות דתיות', 'דתיים', 'POP', '1'),\n",
    "]\n",
    "\n",
    "new_df = pd.DataFrame(index=pivoted_df.index)\n",
    "for col, source, normalizer, *annotations in configuration:\n",
    "    new_df[col] = pivoted_df[source]\n",
    "    if normalizer == 'POP':\n",
    "        new_df[col] = new_df[col] / POP\n",
    "    elif normalizer == 'EXPENSE':\n",
    "        new_df[col] = new_df[col] / EXPENSE\n",
    "    elif normalizer == 'ARNONA_AREA':\n",
    "        new_df[col] = new_df[col] / ARNONA_AREA\n",
    "    elif normalizer == 'AREA':\n",
    "        new_df[col] = new_df[col] / AREA\n",
    "    elif normalizer == 'STUDENTS':\n",
    "        new_df[col] = new_df[col] / STUDENTS\n",
    "\n",
    "new_df['מועצה אזורית'] = (pivoted_df['כללי - מעמד מוניציפלי'] == 'מועצה אזורית')*1\n",
    "\n",
    "DISSIMILARITY_COLUMNS = [\n",
    "    'דירות שנבנו ב-2021', 'דירות למגורים', 'מקרי סכרת לשנה', 'מקרי סרטן לשנה',\n",
    "       'פטירות לשנה', 'פטירת תינוקות', 'לידות לשנה', 'שיעור פריון',\n",
    "       'ריבוי אוכלוסיה', \n",
    "        'צעירים מתחת לגיל 17',\n",
    "       'מבוגרים מעל גיל 65', 'דרוזים', 'יהודים',\n",
    "       'מוסלמים', 'נוצרים', 'נישאים', 'מתגרשים', 'עולים חדשים',\n",
    "       'צפיפות אוכלוסיה', 'מדד חברתי-כלכלי',\n",
    "       'הכנסות ארנונה לא למגורים', 'הכנסות ארנונה למגורים',\n",
    "       'הכנסות מלוות איזון', 'השתתפות משרדי הממשלה', 'שטח חקלאי',\n",
    "       'שטח עסקים', 'זכאים לבגרות', 'ממוצע תלמידים לכיתה', 'סטודנטים',\n",
    "       'תלמידים למורה', 'תלמידים נושרים', 'פארקים',\n",
    "       'מקבלי דמי אבטלה', 'מקבלי הבטחת הכנסה', 'מרוויחי שכר מינימום',\n",
    "       'אי שויון כלכלי', 'ילדים במשפחות עם 5+ ילדים', 'שכירים', 'עצמאים',\n",
    "       'שכר ממוצע', 'מצביעים למפלגות חרדיות', 'מצביעי שמאל', 'מצביעי ימין', 'מצביעי מרכז', 'מצביעים למפלגות ערביות',\n",
    "]\n",
    "\n",
    "# Find which indexes in new_df don't exist in VOTERS:\n",
    "indexes = [x for x in new_df.index if x not in VOTERS.index.values]\n",
    "# print(indexes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle missing values\n",
    "imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "data_imputed = imputer.fit_transform(new_df)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "data_scaled = scaler.fit_transform(data_imputed)\n",
    "pivoted_df_scaled = pd.DataFrame(data_scaled, columns=new_df.columns, index=new_df.index)\n",
    "print(pivoted_df_scaled['מועצה אזורית'])\n",
    "\n",
    "# Apply PCA\n",
    "n_components = 3\n",
    "pca = PCA(n_components='mle')#n_components)  # for example, reduce to 2 dimensions\n",
    "principal_components = pca.fit_transform(data_scaled)\n",
    "n_components = len(pca.components_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explained variance ratio\n",
    "explained_variance_ratio = pca.explained_variance_ratio_\n",
    "\n",
    "# Print the explained variance ratio for each principal component\n",
    "for i, variance in enumerate(explained_variance_ratio):\n",
    "    print(f\"Principal Component {i+1}: {variance:.2f}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_ = []\n",
    "count = 7\n",
    "for i in range(count):\n",
    "    print_.append([])\n",
    "\n",
    "# Sort by the absolute value of the weights\n",
    "for i in range(n_components):\n",
    "    # Match each weight with its corresponding feature\n",
    "    component = pca.components_[i]\n",
    "    feature_weights = zip(new_df.columns, component)\n",
    "    sorted_features = sorted(feature_weights, key=lambda x: np.abs(x[1]), reverse=True)[:count]\n",
    "    for j, (feature, weight) in enumerate(sorted_features):\n",
    "        print_[j].append(f\"{feature:30s}: {weight:5.2f}\")\n",
    "\n",
    "for i in range(count):\n",
    "    print('\\t\\t'.join(print_[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILES = {\n",
    "    'configuration': dict(\n",
    "        columns=dict(\n",
    "            (x[0], dict(norm=x[2], annotations=x[3:])) for x in configuration\n",
    "        )\n",
    "    ),\n",
    "    'settlements': SETT_TO_MUNI,\n",
    "    'cities': dict(\n",
    "        (city_name, dict(\n",
    "            norm=dict(\n",
    "                POP=POP.loc[city_name],\n",
    "                EXPENSE=EXPENSE.loc[city_name],\n",
    "                ARNONA_AREA=ARNONA_AREA.loc[city_name],\n",
    "                AREA=AREA.loc[city_name],\n",
    "                STUDENTS=STUDENTS.loc[city_name]\n",
    "            ),\n",
    "            values=dict(\n",
    "                (col, pivoted_df.loc[city_name][orig_col])\n",
    "                for col, orig_col, *_ in configuration\n",
    "                if not np.isnan(pivoted_df.loc[city_name][orig_col])\n",
    "            ),\n",
    "            orig=dict(\n",
    "                (col, pivoted_df.loc[city_name][col])\n",
    "                for col in pivoted_df.columns\n",
    "                if (not np.isreal(pivoted_df.loc[city_name][col]) or not np.isnan(pivoted_df.loc[city_name][col]))\n",
    "            ),\n",
    "            supports=ENTITY_SUPPORTS.get(pivoted_df.loc[city_name]['entity_id'])\n",
    "        )) for city_name in all_city_names\n",
    "    ),\n",
    "    'distances': dict()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import pairwise_distances\n",
    "from scipy.stats import norm\n",
    "import json\n",
    "\n",
    "# Create a DataFrame with the principal components\n",
    "principal_df = pd.DataFrame(data = principal_components, \n",
    "                            columns = [f'x{i}' for i in range(n_components)],\n",
    "                            index = pivoted_df.index)\n",
    "\n",
    "distances = pairwise_distances(principal_df, metric='euclidean')\n",
    "\n",
    "# Find the indices of the 5 nearest neighbors for each row\n",
    "nearest_neighbors = np.argsort(distances, axis=1)[:, 1:]  # Exclude the first one as it will be the row itself\n",
    "\n",
    "# Create a dictionary or DataFrame to store the nearest neighbors\n",
    "nearest_dict = {}\n",
    "for idx, neighbors in enumerate(nearest_neighbors):\n",
    "    nearest_dict[principal_df.index[idx]] = principal_df.index[neighbors].tolist()\n",
    "\n",
    "def config_for_column(col):\n",
    "    for conf in configuration:\n",
    "        if conf[0] == col:\n",
    "            return conf[1], conf[2]\n",
    "    return None\n",
    "\n",
    "for city_name in all_city_names:\n",
    "    print(f'S{city_name}:')\n",
    "\n",
    "    original_city = new_df.loc[city_name]\n",
    "    nearest_cities = nearest_dict[city_name]\n",
    "    muni_status = new_df.loc[city_name]['מועצה אזורית']\n",
    "    distances = []\n",
    "    for nearest_city in nearest_cities:\n",
    "\n",
    "        # print(f'\\t{nearest_city}:')\n",
    "        original_nearest_city = new_df.loc[nearest_city]\n",
    "        if muni_status != original_nearest_city['מועצה אזורית']:\n",
    "            continue\n",
    "\n",
    "        row1 = pivoted_df_scaled.loc[city_name, DISSIMILARITY_COLUMNS]\n",
    "        row2 = pivoted_df_scaled.loc[nearest_city, DISSIMILARITY_COLUMNS]\n",
    "        abs_diff = np.abs(norm.cdf(row1) - norm.cdf(row2))\n",
    "        differences = list(zip(abs_diff, DISSIMILARITY_COLUMNS))\n",
    "        differences = sorted(differences, key=lambda x: x[0], reverse=True)\n",
    "        distances.append([nearest_city, differences])\n",
    "        if len(distances) == 5:\n",
    "            break\n",
    "\n",
    "    city_names = [x[0] for x in distances]\n",
    "    max_diff = 0\n",
    "    per_city = {}\n",
    "    used_metrics = set()\n",
    "    while len(distances) > 0:\n",
    "        max_diff = 0\n",
    "        max_diff_city = None\n",
    "        max_diff_col = None\n",
    "        max_diff_entry = None\n",
    "        for entry in distances:\n",
    "            if max_diff < entry[1][0][0]:\n",
    "                max_diff = entry[1][0][0]\n",
    "                max_diff_city = entry[0]\n",
    "                max_diff_col = entry[1][0][1]\n",
    "                max_diff_entry = entry\n",
    "        max_diff_entry[1].pop(0)\n",
    "        if len(max_diff_entry[1]) == 0:\n",
    "            distances.remove(max_diff_entry)\n",
    "        if max_diff_col in used_metrics:\n",
    "            continue\n",
    "        used_metrics.add(max_diff_col)\n",
    "        per_city_cols = per_city.setdefault(max_diff_city, [])\n",
    "        per_city_cols.append(max_diff_col)\n",
    "        if len(per_city_cols) == 4:\n",
    "            distances.remove(max_diff_entry)\n",
    "\n",
    "    distances = [[k, per_city[k]] for k in city_names]    \n",
    "    FILES['distances'][city_name] = distances\n",
    "\n",
    "\n",
    "\n",
    "for k, v in FILES.items():\n",
    "    with open(f'../src/assets/{k}.json', 'w') as json_output:\n",
    "        json.dump(v, json_output, ensure_ascii=False, sort_keys=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "\n",
    "RULES = [\n",
    "    ('יותר דתית', 'יותר חילונית', 'מצביעים למפלגות דתיות'),\n",
    "    ('יותר חמה', 'יותר קרה', 'טמפרטורה ממוצעת באוגוסט'),\n",
    "    ('יותר מרכזית', 'יותר פריפריאלית', 'מרחק מתל אביב'),\n",
    "    ('יותר ימנית', 'יותר שמאלנית', 'מצביעים למפלגות הקואליציה'),\n",
    "    ('יותר תושבים', 'פחות תושבים', 'מספר תושבים'),\n",
    "    ('יותר צפופה', 'פחות צפופה', 'צפיפות אוכלוסיה'),\n",
    "    ('יותר עשירה', 'יותר ענייה', 'מדד חברתי-כלכלי'),    \n",
    "]\n",
    "DIFF = 0.1\n",
    "MORE = lambda x,c,v: x[c] > v\n",
    "LESS = lambda x,c,v: x[c] < v\n",
    "RULES = [(c[0], c[2], MORE, DIFF) for c in RULES] + [(c[1], c[2], LESS, -DIFF) for c in RULES]\n",
    "\n",
    "likes = []\n",
    "for city_name in all_city_names:\n",
    "    print(f'L {city_name}:')\n",
    "\n",
    "    original_city = pivoted_df_scaled.loc[city_name]\n",
    "    nearest_cities = nearest_dict[city_name]\n",
    "    muni_status = original_city['מועצה אזורית']\n",
    "\n",
    "    rec = []\n",
    "    for rule, col, condition, diff in RULES:\n",
    "        if condition(original_city, col, 0):\n",
    "            continue\n",
    "        # diff_val = original_city[col] + diff\n",
    "        diff_val = norm.ppf(norm.cdf(original_city[col])+diff)\n",
    "        assert not np.isnan(diff_val)\n",
    "        found = []\n",
    "        for nearest_city in nearest_cities:\n",
    "            # print(f'\\t{nearest_city}:')\n",
    "            original_nearest_city = pivoted_df_scaled.loc[nearest_city]\n",
    "            if muni_status != original_nearest_city['מועצה אזורית']:\n",
    "                continue\n",
    "            if condition(original_nearest_city, col, diff_val):\n",
    "                nearest_city_val = original_nearest_city[col]\n",
    "                diff_val = abs(nearest_city_val - diff_val)\n",
    "                found.append(dict(val=diff_val, city=nearest_city))\n",
    "                # print(f'\\t\\t{rule}: o{original_city[col]}o, {diff}, z{diff_val}z')\n",
    "                # print(f'\\t\\t\\t{nearest_city}: {original_nearest_city[col]}')\n",
    "            if len(found) == 10:\n",
    "                break\n",
    "        if found:\n",
    "            rec.append(dict(rule=rule, found=found))\n",
    "\n",
    "    rules = []\n",
    "    used_cities = set()\n",
    "    while len(rec) > 0:\n",
    "        rec = sorted(rec, key=lambda x: x['found'][0]['val'])\n",
    "        found_city = rec[0]['found'][0]['city']\n",
    "        if found_city in used_cities:\n",
    "            rec[0]['found'].pop(0)\n",
    "            if not rec[0]['found']:\n",
    "                rec.pop(0)\n",
    "            continue\n",
    "        rule = rec[0]['rule']\n",
    "        rules.append([rule, found_city])\n",
    "        print(f'\\t\\tקצת {rule}: {found_city}')\n",
    "        used_cities.add(found_city)\n",
    "        rec.pop(0)\n",
    "    likes.append([city_name, rules])\n",
    "\n",
    "\n",
    "\n",
    "with open(f'./likes.json', 'w') as json_output:\n",
    "    json.dump(likes, json_output, ensure_ascii=False, sort_keys=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.manifold import TSNE\n",
    "# import matplotlib.pyplot as plt\n",
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# # Extract the color values from the original DataFrame\n",
    "# color_values = new_df['אחוז גביית ארנונה'].values\n",
    "\n",
    "# scaler = MinMaxScaler()\n",
    "# color_values_scaled = scaler.fit_transform(color_values.reshape(-1, 1)).flatten()\n",
    "\n",
    "# # Apply t-SNE\n",
    "# tsne = TSNE(n_components=2, random_state=42)  # You can adjust the parameters as needed\n",
    "# tsne_results = tsne.fit_transform(principal_components)\n",
    "\n",
    "# # Create a scatter plot of the t-SNE output\n",
    "# plt.figure(figsize=(6, 6))  # 6x6 inches plot\n",
    "# plt.scatter(principal_components[:, 0], principal_components[:, 1], c=color_values_scaled, cmap='viridis')\n",
    "# # plt.scatter(tsne_results[:, 0], tsne_results[:, 1], c=color_values_scaled, cmap='viridis')\n",
    "\n",
    "# # # Optionally add labels, titles, etc.\n",
    "# # plt.title(\"t-SNE of PCA Results\")\n",
    "# # plt.xlabel(\"t-SNE Feature 1\")\n",
    "# # plt.ylabel(\"t-SNE Feature 2\")\n",
    "\n",
    "# # Save the plot as a 600x600 PNG image\n",
    "# plt.savefig(\"tsne_output.png\", dpi=100)  # 100 dpi results in a 600x600 image\n",
    "# plt.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
